(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{492:function(v,a,e){v.exports=e.p+"assets/img/image-20221008103827810.89efed7f.png"},493:function(v,a,e){v.exports=e.p+"assets/img/image-20221008112916180.dd059fe4.png"},494:function(v,a,e){v.exports=e.p+"assets/img/wps2.868a3ba0.jpg"},495:function(v,a,e){v.exports=e.p+"assets/img/wps3.c40f0d2d.jpg"},496:function(v,a,e){v.exports=e.p+"assets/img/wps4.6b31be7a.jpg"},497:function(v,a,e){v.exports=e.p+"assets/img/wps5.9c1112f2.jpg"},498:function(v,a,e){v.exports=e.p+"assets/img/wps6.a1a54d93.jpg"},499:function(v,a,e){v.exports=e.p+"assets/img/wps7.96810d99.jpg"},500:function(v,a,e){v.exports=e.p+"assets/img/wps8.36d11e9f.jpg"},501:function(v,a,e){v.exports=e.p+"assets/img/wps9.0d7fba98.jpg"},502:function(v,a,e){v.exports=e.p+"assets/img/wps10.51169b3f.jpg"},503:function(v,a,e){v.exports=e.p+"assets/img/wps11.b7139987.jpg"},504:function(v,a,e){v.exports=e.p+"assets/img/wps12.d0c4ff8d.jpg"},505:function(v,a,e){v.exports=e.p+"assets/img/wps13.dfecff3b.jpg"},506:function(v,a,e){v.exports=e.p+"assets/img/wps14.00c3e1f3.jpg"},507:function(v,a,e){v.exports=e.p+"assets/img/wps15.ef30af89.jpg"},508:function(v,a,e){v.exports=e.p+"assets/img/wps16.6102587a.jpg"},509:function(v,a,e){v.exports=e.p+"assets/img/wps17.e940505a.jpg"},778:function(v,a,e){"use strict";e.r(a);var t=e(31),_=Object(t.a)({},(function(){var v=this,a=v.$createElement,t=v._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("h2",{attrs:{id:"组件介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#组件介绍"}},[v._v("#")]),v._v(" 组件介绍")]),v._v(" "),t("table",[t("thead",[t("tr",[t("th",[v._v("服务")]),v._v(" "),t("th",[v._v("版本")]),v._v(" "),t("th",[v._v("描述")])])]),v._v(" "),t("tbody",[t("tr",[t("td",[v._v("HDFS")]),v._v(" "),t("td",[v._v("3.2.0")]),v._v(" "),t("td",[v._v("Apache Hadoop 分布式文件系统")])]),v._v(" "),t("tr",[t("td",[v._v("YARN")]),v._v(" "),t("td",[v._v("3.2.0")]),v._v(" "),t("td",[v._v("通用资源管理系统")])]),v._v(" "),t("tr",[t("td",[v._v("MapReduce")]),v._v(" "),t("td",[v._v("23.2.0")]),v._v(" "),t("td",[v._v("MapReduce是一种编程模型，用于大规模数据集的并行运算")])]),v._v(" "),t("tr",[t("td",[v._v("Tez")]),v._v(" "),t("td",[v._v("0.9.1")]),v._v(" "),t("td",[v._v("是在YARN之上编写的下一代Hadoop查询处理框架。")])]),v._v(" "),t("tr",[t("td",[v._v("Hive")]),v._v(" "),t("td",[v._v("3.1.2")]),v._v(" "),t("td",[v._v("用于大数据集即席查询分析和表存储管理服务的数据仓库系统")])]),v._v(" "),t("tr",[t("td",[v._v("HBase")]),v._v(" "),t("td",[v._v("2.2.6")]),v._v(" "),t("td",[v._v("用于配置管理和同步的非关系分布式数据库和集中式服务")])]),v._v(" "),t("tr",[t("td",[v._v("Sqoop")]),v._v(" "),t("td",[v._v("1.4.7")]),v._v(" "),t("td",[v._v("用于在Apache Hadoop和结构化数据存储（如关系数据库）之间传输大量数据的工具")])]),v._v(" "),t("tr",[t("td",[v._v("ZooKeeper")]),v._v(" "),t("td",[v._v("3.5.9")]),v._v(" "),t("td",[v._v("提供高度可靠的分布式协调的集中式服务")])]),v._v(" "),t("tr",[t("td",[v._v("Infra Solr")]),v._v(" "),t("td",[v._v("1.0.0")]),v._v(" "),t("td",[v._v("Wdp托管组件使用的核心共享服务。")])]),v._v(" "),t("tr",[t("td",[v._v("Wdp Metrics")]),v._v(" "),t("td",[v._v("1.0.0")]),v._v(" "),t("td",[v._v("度量收集系统，为从集群收集的度量提供存储和检索能力")])]),v._v(" "),t("tr",[t("td",[v._v("Kafka")]),v._v(" "),t("td",[v._v("2.5.0")]),v._v(" "),t("td",[v._v("一种高吞吐量的分布式消息传递系统")])]),v._v(" "),t("tr",[t("td",[v._v("Knox")]),v._v(" "),t("td",[v._v("1.6.1")]),v._v(" "),t("td",[v._v("为集群中的 Apache Hadoop 服务提供单点身份验证和访问")])]),v._v(" "),t("tr",[t("td",[v._v("Log Search")]),v._v(" "),t("td",[v._v("0.5.0")]),v._v(" "),t("td",[v._v("WDP平台的日志聚合、分析和可视化工具")])]),v._v(" "),t("tr",[t("td",[v._v("Ranger")]),v._v(" "),t("td",[v._v("2.2.0")]),v._v(" "),t("td",[v._v("Ranger是一个跨Hadoop平台启用、监视和管理全面数据安全的框架。")])]),v._v(" "),t("tr",[t("td",[v._v("Ranger KMS")]),v._v(" "),t("td",[v._v("1.0.0")]),v._v(" "),t("td",[v._v("密钥管理服务器")])]),v._v(" "),t("tr",[t("td",[v._v("Spark")]),v._v(" "),t("td",[v._v("3.2.1")]),v._v(" "),t("td",[v._v("Apache Spark是一个用于大规模数据处理的快速通用引擎。")])]),v._v(" "),t("tr",[t("td",[v._v("Zeppelin Notebook")]),v._v(" "),t("td",[v._v("0.10.1")]),v._v(" "),t("td",[v._v("支持交互式数据分析的基于 Web 的笔记本。它使您能够使用 SQL、Scala 等制作精美的数据驱动、交互式和协作文档。")])]),v._v(" "),t("tr",[t("td",[v._v("Alluxio")]),v._v(" "),t("td",[v._v("2.5.0")]),v._v(" "),t("td",[v._v("以内存为中心的可靠分布式存储")])]),v._v(" "),t("tr",[t("td",[v._v("Clickhouse")]),v._v(" "),t("td",[v._v("21.8.3.44-2")]),v._v(" "),t("td",[v._v("开源的分布式列式存储数据库")])]),v._v(" "),t("tr",[t("td",[v._v("Elasticsearch")]),v._v(" "),t("td",[v._v("7.16.2")]),v._v(" "),t("td",[v._v("Elasticsearch 是一个高度可扩展且开源的全文检索和分析引擎,它可以让你快速的且近实时地存储，检索以及分析海量数据。")])]),v._v(" "),t("tr",[t("td",[v._v("Flink")]),v._v(" "),t("td",[v._v("1.15.1")]),v._v(" "),t("td",[v._v("Apache Flink是一个流式数据流引擎，它为数据流上的分布式计算提供数据分发、通信和容错。")])]),v._v(" "),t("tr",[t("td",[v._v("Kerberos")]),v._v(" "),t("td",[v._v("1.10.3")]),v._v(" "),t("td",[v._v('一种计算机网络身份验证协议，它以"票证"为基础，允许在非安全网络上通信的节点以安全的方式相互证明其身份')])]),v._v(" "),t("tr",[t("td",[v._v("OZONE")]),v._v(" "),t("td",[v._v("1.2.0")]),v._v(" "),t("td",[v._v("APACHE OZONE")])]),v._v(" "),t("tr",[t("td",[v._v("Presto")]),v._v(" "),t("td",[v._v("0.250")]),v._v(" "),t("td",[v._v("Presto是一个开源的分布式SQL查询引擎，用于对从GB到PB的各种大小的数据源运行交互式分析查询")])])])]),v._v(" "),t("h2",{attrs:{id:"图结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#图结构"}},[v._v("#")]),v._v(" 图结构")]),v._v(" "),t("p",[t("img",{attrs:{src:e(492),alt:"image-20221008103827810"}})]),v._v(" "),t("h2",{attrs:{id:"功能架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#功能架构"}},[v._v("#")]),v._v(" 功能架构")]),v._v(" "),t("p",[t("img",{attrs:{src:e(493),alt:"image-20221008112916180"}})]),v._v(" "),t("p",[v._v("WDP包括集群管理，分布式存储，分布式资源管理，分布式计算引擎，SQL查询引擎，数据集成等模块")]),v._v(" "),t("ul",[t("li",[t("strong",[v._v("集群管理")]),v._v("：主要有HADOOP软件源管理，组件配置管理，运维监控，安全管理，租户管理，备份管理等功能；")]),v._v(" "),t("li",[v._v("**分布式存储管理：**使用分布式文件系统HDFS作为底层的存储，支持NOSQL查询数据库HBASE，ES索引，ORC,PARQUET存储格式等；")]),v._v(" "),t("li",[v._v("**分布式资源原理：**使用HADOOP组件YARN作为集群资源队列管理器，分布式计算作业都统一提交到YARN上运行；")]),v._v(" "),t("li",[v._v("**分布式计算引擎：**支持经典的HADOOP分布式计算引擎MR, 默认使用新一代的TEZ内存计算引擎作为HIVE的计算引擎，集成内存计算SPARK,实时计算框架FLINK；")]),v._v(" "),t("li",[t("strong",[v._v("SQL查询引擎")]),v._v("：支持主流的批量SQL处理引擎HIVE-SQL, SPARK-SQL，引入了实时交互查询引擎 Presto，IMPALA")]),v._v(" "),t("li",[v._v("**数据集成：**集成SQOOP模块作为关系型数据库导入到HIVE库的组件，集成KAFKA消息中间件。通过对接全程调度和数据工厂，支持复杂的ETL作业和数据开发；")])]),v._v(" "),t("h2",{attrs:{id:"组件清单"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#组件清单"}},[v._v("#")]),v._v(" 组件清单")]),v._v(" "),t("p",[v._v("WDP 需要对开源组件进行集成和封装，实现进行统一的配置监控和运维，对外提供分布式存储，批处理，实时处理，交互式查询等大数据能力，组件清单如下：")]),v._v(" "),t("h3",{attrs:{id:"wdp-server"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#wdp-server"}},[v._v("#")]),v._v(" WDP-SERVER")]),v._v(" "),t("p",[v._v("WDP-SERVER: 作为运维系统，为WDP提供高可靠、安全、易用的集群管理能力，支持大规模集群的安装/升级/补丁、配置管理、监控管理、告警管理、用户管理、租户管理等。")]),v._v(" "),t("h3",{attrs:{id:"wdp-agent"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#wdp-agent"}},[v._v("#")]),v._v(" WDP-AGENT")]),v._v(" "),t("p",[v._v("WDP-AGENT: 部署在每台主机上的负载进行HADOOP组件安装和监控，日志信息采集，启停等功能的组件。")]),v._v(" "),t("h3",{attrs:{id:"hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs"}},[v._v("#")]),v._v(" HDFS")]),v._v(" "),t("p",[v._v("HDFS: 是Hadoop的分布式文件系统，提供高吞吐量的数据访问，来实现流式读取文件系统数据的目的。它保证一个文件在一个时刻只被一个调用者执行写操作，而可以被多个调用者执行读操作，可以实现大规模数据可靠的分布式读写。")]),v._v(" "),t("p",[v._v("分布式文件系统HDFS")]),v._v(" "),t("p",[t("img",{attrs:{src:e(494),alt:"img"}})]),v._v(" "),t("ul",[t("li",[v._v("HDFS采用master/slave架构。一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。Namenode是一个中心服务器，负责管理文件系统的名字空间以及客户端对文件的访问。集群中的Datanode一般是一个节点一个，负责管理它所在节点上的存储。")]),v._v(" "),t("li",[v._v("从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制。")]),v._v(" "),t("li",[v._v("HDFS是一个主从结构，一个HDFS集群是由一个名字节点，它是一个管理文件命名空间和调节客户端访问文件的主服务器，当然还有一些数据节点，通常是一个节点一个机器，它来管理对应节点的存储。HDFS对外开放文件命名空间并允许用户数据以文件形式存储。")])]),v._v(" "),t("h3",{attrs:{id:"yarn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#yarn"}},[v._v("#")]),v._v(" YARN")]),v._v(" "),t("p",[v._v("YARN: Hadoop生态的资源管理系统，它是一个通用的资源模块，大大减小了ResourceManager的资源消耗，并且让监测每一个 Job 子任务状态的程序分布式化，可以为各类应用程序进行资源管理和调度。")]),v._v(" "),t("p",[v._v("YARN的架构及各角色职责")]),v._v(" "),t("p",[t("img",{attrs:{src:e(495),alt:"img"}})]),v._v(" "),t("ul",[t("li",[v._v("YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 Application Master 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，Application Master 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。")]),v._v(" "),t("li",[v._v("Application Master 管理一个在 YARN 内运行的应用程序的每个实例。Application Master 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。")]),v._v(" "),t("li",[v._v("NodeManager 管理一个 YARN 集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。")])]),v._v(" "),t("p",[v._v("统一资源管理和调度框架YARN")]),v._v(" "),t("p",[t("img",{attrs:{src:e(496),alt:"img"}})]),v._v(" "),t("h3",{attrs:{id:"mapreduce"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce"}},[v._v("#")]),v._v(" MAPREDUCE")]),v._v(" "),t("p",[v._v("MAPREDUCE：MapReduce是Hadoop的核心，是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算，提供快速并行处理大量数据的能力，是一种分布式数据处理模式和执行环境。MapReduce是面向大数据并行处理的计算模型、框架和平台。当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（化简）函数，用来保证所有映射的键值对中的每一个共享相同的键组。")]),v._v(" "),t("p",[v._v("分布式批处理引擎")]),v._v(" "),t("p",[t("img",{attrs:{src:e(497),alt:"img"}})]),v._v(" "),t("ul",[t("li",[v._v("作为一个基于集群的高性能并行计算平台，它允许用市场上普通的商用服务器构成一个包含数十、数百至数千个节点的分布和并行计算集群。")]),v._v(" "),t("li",[v._v("作为一个并行计算与运行软件框架，它提供了一个庞大但设计精良的并行计算软件框架，能自动完成计算任务的并行化处理，自动划分计算数据和计算任务，在集群节点上自动分配和执行任务以及收集计算结果，将数据分布存储、数据通信、容错处理等并行计算涉及到的很多系统底层的复杂细节交由系统负责处理，大大减少了软件开发人员的负担。")]),v._v(" "),t("li",[v._v("作为一个并行程序设计模型与方法，它用Map和Reduce两个函数编程实现基本的并行计算任务，提供了抽象的操作和并行编程接口，以简单方便地完成大规模数据的编程和计算处理。Reduce函数接受Map函数生成的列表，然后根据它们的键缩小键/值对列表。")])]),v._v(" "),t("p",[v._v("MapReduce工作流程概述")]),v._v(" "),t("p",[t("img",{attrs:{src:e(498),alt:"img"}})]),v._v(" "),t("p",[v._v("MapReduce起到了将大事务分散到不同设备处理的能力，这使得原本必须用单台较强服务器才能运行的任务，在分布式环境下也能完成了。")]),v._v(" "),t("h3",{attrs:{id:"hive"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive"}},[v._v("#")]),v._v(" HIVE")]),v._v(" "),t("p",[v._v("HIVE: Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型， Hadoop监控作业执行过程，然后返回作业执行结果给用户，非常适合大数据集的批处理作业。")]),v._v(" "),t("p",[t("strong",[v._v("Hive与Hadoop的关系")])]),v._v(" "),t("p",[t("img",{attrs:{src:e(499),alt:"img"}})]),v._v(" "),t("p",[v._v("Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行。Hive在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS中Hive设定的目录下。")]),v._v(" "),t("p",[t("strong",[v._v("Hive")]),v._v("架构图")]),v._v(" "),t("p",[t("img",{attrs:{src:e(500),alt:"img"}})]),v._v(" "),t("ul",[t("li",[v._v("用户接口主要有三个：CLI，Client 和 WUI。其中最常用的是 CLI，CLI启动的时候，会同时启动一个 Hive 副本。 Client 是 Hive 的客户端，用户连接至 Hive Server。在启动 Client 模式的时候， 需要指出 Hive Server 所在节点，并且在该节点启动 Hive Server。WUI 是通过浏览器访问 Hive。")]),v._v(" "),t("li",[v._v("元数据存储：Hive 将元数据存储在数据库中，如 mysql、derby、Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。")])]),v._v(" "),t("h3",{attrs:{id:"hbase"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase"}},[v._v("#")]),v._v(" HBASE")]),v._v(" "),t("p",[v._v("HBASE: HBASE是一种NoSQL数据库，提供海量数据存储功能，是一种构建在HDFS之上的面向列、高可靠性、高性能的分布式存储系统，一种适合存储海量非结构化数据或半结构化数据的可灵活扩展伸缩的、支持实时数据读写的分布式存储系统。")]),v._v(" "),t("p",[v._v("分布式数据库HBase")]),v._v(" "),t("p",[t("img",{attrs:{src:e(501),alt:"img"}})]),v._v(" "),t("p",[v._v("它支持强读写一致，但是不是“最终一致性”的数据存储，这使得它非常适合高速的计算聚合。Hbase提供了内置的web界面来操作，还可以监控JMX指标。在Hbase中，表被分割成多个更小的块然后分散的存储在不同的服务器上，这些小块叫做Regions，存放Regions的地方叫做RegionServer。Master进程负责处理不同的RegionServer之间的Region的分发。在Hbase实现中HRegionServer和HRegion类代表RegionServer和Region。HRegionServer除了包含一些HRegions之外，还处理两种类型的文件用于数据存储：HLog预写日志文件和HFile 真实的数据存储文件。")]),v._v(" "),t("p",[v._v("存储在HBase中的表的典型特征：")]),v._v(" "),t("ul",[t("li",[v._v("大表（BigTable）：一个表可以有上亿行，上百万列")]),v._v(" "),t("li",[v._v("面向列：面向列(族)的存储、检索与权限控制")]),v._v(" "),t("li",[v._v("稀疏：表中为空(null)的列不占用存储空间")])]),v._v(" "),t("h3",{attrs:{id:"spark"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark"}},[v._v("#")]),v._v(" SPARK")]),v._v(" "),t("p",[v._v("SPARK: 是专为大规模数据处理而设计的快速通用的计算引擎，是基于内存进行计算的分布式计算框架。Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载，可用来构建大型的、低延迟的数据分析应用程序。并且，Spark同时提供了操作允许用户显示的将数据转换过程持久化到硬盘。对于数据本地化，是通过允许用户能够基于每条记录的键值，控制数据分区实现的。如果内存的使用超过了物理限制，Spark将会把这些比较大的分区写入到硬盘，由此来保证可扩展性。")]),v._v(" "),t("p",[v._v("Spark集群架构示意图")]),v._v(" "),t("p",[t("img",{attrs:{src:e(502),alt:"img"}})]),v._v(" "),t("ul",[t("li",[v._v("Spark提供了一个快速的计算，写入，以及交互式查询的框架。相比于Hadoop，Spark拥有明显的性能优势。Spark使用in-memory的计算方式，通过这种方式来避免一个MapReduce工作流中的多个任务对同一个数据集进行计算时的IO瓶颈。Spark利用Scala语言实现，Scala能够使得处理分布式数据集时，能够像处理本地化数据一样。")]),v._v(" "),t("li",[v._v("除了交互式的数据分析，Spark还能够支持交互式的数据挖掘，由于Spark是基于内存的计算，很方便处理迭代计算，而数据挖掘的问题通常都是对同一份数据进行迭代计算。除此之外，Spark能够运行于安装Hadoop 2.0 Yarn的集群。之所以Spark能够在保留MapReduce容错性，数据本地化，可扩展性等特性的同时，能够保证性能的高效，并且避免繁忙的磁盘IO，主要原因是因为Spark创建了一种叫做RDD（Resilient Distributed Dataset）的内存抽象结构。")]),v._v(" "),t("li",[v._v("原有的分布式内存抽象，例如key-value store以及数据库，支持对于可变状态的细粒度更新，这一点要求集群需要对数据或者日志的更新进行备份来保障容错性。这样就会给数据密集型的工作流带来大量的IO开销。而对于RDD来说，它只有一套受限制的接口，仅仅支持粗粒度的更新，例如map，join等等。通过这种方式，Spark只需要简单的记录建立数据的转换操作的日志，而不是完整的数据集，就能够提供容错性。这种数据的转换链记录就是数据集的溯源。由于并行程序，通常是对一个大数据集应用相同的计算过程，因此之前提到的粗粒度的更新限制并没有想象中的大。事实上，Spark论文中阐述了RDD完全可以作为多种不同计算框架，例如MapReduce，Pregel等的编程模型。")]),v._v(" "),t("li",[v._v("并且，Spark同时提供了操作允许用户显示的将数据转换过程持久化到硬盘。对于数据本地化，是通过允许用户能够基于每条记录的键值，控制数据分区实现的。（采用这种方式的一个明显好处是，能够保证两份需要进行关联的数据将会被同样的方式进行哈希）。如果内存的使用超过了物理限制，Spark将会把这些比较大的分区写入到硬盘，由此来保证可扩展性。")])]),v._v(" "),t("h3",{attrs:{id:"zookeeper"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zookeeper"}},[v._v("#")]),v._v(" ZOOKEEPER")]),v._v(" "),t("p",[v._v("ZOOKEEPER：ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能，是一个分布式的、开放源码的分布式应用程序协调服务。ZooKeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心。服务生产者将自己提供的服务注册到 ZooKeeper 中心，服务的消费者在进行服务调用的时候先到 ZooKeeper 中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。      ZooKeeper帮助系统避免单点故障，从而建立可靠的应用程序。目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。并且使用Zookeeper可以保证总服务器自动感知有多少提供搜索引擎的服务器并向这些服务器发出搜索请求，当总服务器宕机时自动启用备用的总服务器。")]),v._v(" "),t("h3",{attrs:{id:"tez"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tez"}},[v._v("#")]),v._v(" TEZ")]),v._v(" "),t("p",[v._v("TEZ：旨在构建一个应用程序框架，该框架允许使用复杂的有向无环图来处理数据。TEZ提供了一个可重用，灵活的框架来支持数据流模型。Tez是支持DAG作业的计算框架，它直接源于MapReduce框架，核心思想是将Map和Reduce两个操作进一步拆分成多个阶段，分解后的元操作可以任意灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可形成一个大的DAG作业落地。Tez可以将多个有依赖的作业转换为一个作业，这样只需写一次HDFS，且中间节点较少。")]),v._v(" "),t("p",[v._v("MapReduce和Tez对比")]),v._v(" "),t("p",[t("img",{attrs:{src:e(503),alt:"img"}})]),v._v(" "),t("h3",{attrs:{id:"ranger"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ranger"}},[v._v("#")]),v._v(" RANGER")]),v._v(" "),t("p",[v._v("RANGER：提供HADOOP生态组件的统一权限配置能力，是大数据领域一个集中式安全管理框架，并解决授权和审计，是Hadoop生态的综合安全管理组件。通过制定策略实现对诸如HDFS、Yarn、Hive、Kafka、HBase、Storm等组件进行细粒度的权限控制。通过Ranger控制台，管理员通过配置策略来控制用户访问权限。比如，可以控制用户读取HDFS文件权限，甚至可以控制用户对Hive某列的访问权限。")]),v._v(" "),t("p",[v._v("Ranger组件的组成")]),v._v(" "),t("p",[t("img",{attrs:{src:e(504),alt:"img"}})]),v._v(" "),t("p",[v._v("Ranger主要由三个组件组成：")]),v._v(" "),t("ul",[t("li",[v._v("Ranger Admin：用户可以创建、更新安全访问策略，这些策略被存储在数据库中。各个组件的Plugin定期对这些策略进行轮询。")]),v._v(" "),t("li",[v._v("Ranger Plugins：Plugin嵌入在各个集群组件的进程里，是一个轻量级的Java程序。例如，Ranger对Hive的组件，就被嵌入在Hiveserver2里。这些Plugin从Ranger Admin服务端拉取策略，并把它们存储在本地文件中。当接收到来自组件的用户请求时，对应组件的plugin会拦截该请求，并根据安全策略对其进行评估。")]),v._v(" "),t("li",[v._v("User UserSync：Ranger提供了一个用户同步工具，可以从Unix或者LDAP中拉取用户和用户组的信息。这些用户和用户组的信息被存储在Ranger Admin的数据库中，可以在定义策略时使用。")])]),v._v(" "),t("h3",{attrs:{id:"sqoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sqoop"}},[v._v("#")]),v._v(" SQOOP")]),v._v(" "),t("p",[v._v("SQOOP：是Hadoop和关系数据库服务器之间传送数据的工具，可以将一个关系型数据库中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。它可以高效、可控地利用资源，可以通过调整任务数来控制任务的并发度，也可以自动地完成数据映射和转换。由于导入数据库是有类型的，它可以自动根据数据库中的类型转换到Hadoop 中，当然用户也可以自定义它们之间的映射关系。Sqoop专为大数据批量传输设计，能够分割数据集并创建maptask任务来处理每个区块。")]),v._v(" "),t("p",[v._v("Sqoop的架构示意")]),v._v(" "),t("p",[t("img",{attrs:{src:e(505),alt:"img"}})]),v._v(" "),t("h3",{attrs:{id:"flink"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flink"}},[v._v("#")]),v._v(" FLINK")]),v._v(" "),t("p",[v._v("FLINK：是个分布式的、高可用的、能保证Exactly Once语义的针对流数据和批数据的处理引擎。Flink以数据并行和流水线方式执行任意流数据程序，Flink的流水线运行时系统可以执行批处理和流处理程序。Flink是一个批处理和流处理结合的统一计算框架，其核心是一个提供了数据分发以及并行化计算的流数据处理引擎。它的最大亮点是流处理，是业界最顶级的开源流处理引擎。Flink最适合的应用场景是低时延的数据处理场景：高并发处理数据，时延毫秒级，且兼具可靠性。")]),v._v(" "),t("p",[v._v("Flink技术栈")]),v._v(" "),t("p",[t("img",{attrs:{src:e(506),alt:"img"}})]),v._v(" "),t("p",[v._v("Flink整个系统包含三个部分：")]),v._v(" "),t("ul",[t("li",[v._v("Client：Flink Client主要给用户提供向Flink系统提交用户任务（流式作业）的能力。")]),v._v(" "),t("li",[v._v("TaskManager：Flink系统的业务执行节点，执行具体的用户任务。TaskManager可以有多个，各个TaskManager都平等。")]),v._v(" "),t("li",[v._v("JobManager：Flink系统的管理节点，管理所有的TaskManager，并决策用户任务在哪些Taskmanager执行。JobManager在HA模式下可以有多个，但只有一个主JobManager。")])]),v._v(" "),t("h3",{attrs:{id:"kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[v._v("#")]),v._v(" KAFKA")]),v._v(" "),t("p",[v._v("KAFKA：一个分布式的、分区的、多副本的消息发布-订阅系统，它具有消息持久化、高吞吐、分布式、多客户端支持、实时等特性，适用于离线和在线的消息消费，如常规的消息收集、网站活性跟踪、聚合统计系统运营数据（监控数据）、日志收集等大量数据的互联网服务的数据收集场景。它以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。它有高吞吐率即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。")]),v._v(" "),t("p",[v._v("Kafka架构")]),v._v(" "),t("p",[t("img",{attrs:{src:e(507),alt:"img"}})]),v._v(" "),t("h3",{attrs:{id:"presto"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#presto"}},[v._v("#")]),v._v(" PRESTO")]),v._v(" "),t("p",[v._v("PRESTO：是完全基于内存的并⾏计算、分布式SQL交互式数据查询引擎，可以对不同的数据源实时查询和计算。它的一种大规模并行处理模型，多个节点管道式执⾏支持任意数据源（通过扩展式Connector组件），数据规模GB~PB级使用的技术，如向量计算、动态编译执⾏计划、优化的ORC和Parquet Reader等。适合PB级海量数据复杂分析，交互式SQL查询，⽀持跨数据源查询。")]),v._v(" "),t("p",[v._v("Presto的内部架构")]),v._v(" "),t("p",[t("img",{attrs:{src:e(508),alt:"img"}})]),v._v(" "),t("p",[v._v("这里面三个服务：")]),v._v(" "),t("ul",[t("li",[t("p",[v._v("Coordinator（考第内ter），是一个中心的查询角色，它主要的一个作用是接受查询请求，将他们转换成各种各样的任务，将任务拆解后分发到多个worker去执行各种任务的节点")]),v._v(" "),t("p",[v._v("1、解析SQL语句")]),v._v(" "),t("p",[v._v("2、⽣成执⾏计划")]),v._v(" "),t("p",[v._v("3、分发执⾏任务给Worker节点执⾏")])]),v._v(" "),t("li",[t("p",[v._v("Worker，是一个真正的计算的节点，执行任务的节点，它接收到task后，就会到对应的数据源里面，去把数据提取出来，提取方式是通过各种各样的connector：负责实际执⾏查询任务。")])]),v._v(" "),t("li",[t("p",[v._v("Discovery service，是将coordinator和woker结合到一起的服务：")]),v._v(" "),t("p",[v._v("1、Worker节点启动后向Discovery Server服务注册")]),v._v(" "),t("p",[v._v("2、Coordinator从Discovery Server获得Worker节点")])])]),v._v(" "),t("h3",{attrs:{id:"alluxio"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#alluxio"}},[v._v("#")]),v._v(" ALLUXIO")]),v._v(" "),t("p",[v._v("ALLUXIO：是一个面向基于云的数据分析和人工智能的数据编排技术。Alluxio为数据驱动型应用和存储系统构建了桥梁，将数据从存储层移动到距离数据驱动型应用更近的位置，从而能够更容易被访问。同时使得应用程序能够通过一个公共接口连接到许多存储系统，一个基于内存的分布式存储系统。 它桥接了计算框架和存储系统之间的鸿沟，使计算应用程序可以通过公共接口连接到众多存储系统，并且提供缓存的方式减少IO带宽。Alluxio可以同时管理多个底层文件系统，将不同的文件系统统一在同一个名称空间下，让上层客户端可以自由访问统一名称空间内的不同路径、不同存储系统的数据。")]),v._v(" "),t("p",[v._v("Alluxio架构")]),v._v(" "),t("p",[t("img",{attrs:{src:e(509),alt:"img"}})]),v._v(" "),t("p",[v._v("Alluxio的优势：")]),v._v(" "),t("ul",[t("li",[v._v("提供内存级I/O吞吐率，同时降低具有弹性扩张特性的数据驱动型应用的成本开销。")]),v._v(" "),t("li",[v._v("简化云存储和对象存储接入。")]),v._v(" "),t("li",[v._v("简化数据管理，提供对多数据源的单点访问。")]),v._v(" "),t("li",[v._v("应用程序部署简易。")])]),v._v(" "),t("h2",{attrs:{id:"参考相关"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考相关"}},[v._v("#")]),v._v(" 参考相关")]),v._v(" "),t("ul",[t("li",[v._v("https://help.aliyun.com/document_detail/119077.html#section-rhm-675-819")])])])}),[],!1,null,null,null);a.default=_.exports}}]);